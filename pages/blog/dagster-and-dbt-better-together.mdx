---
layout: 'BlogPost'
status: 'draft'
title: 'Dagster and dbt: Better Together'
excerpt: 'Announcing the dagster-dbt library, a first-class integration for Dagster and dbt projects.'
coverImage: '/posts/dagster-and-dbt-better-together/dagster-dbt.png'
date: '2020-09-24'
authors: ['bobchen168', 'aj_nadel']
---

import { LinkPreview } from 'components/LinkPreview'

We are proud to announce the `dagster-dbt` library, a new first-class integration for Dagster and [dbt](https://www.getdbt.com/product/) (data build tool).

dbt was created by [Fishtown Analytics](https://www.fishtownanalytics.com/) to empower data analysts with tools to build well-defined data transformations in an intuitive, testable, and versioned environment. We love dbt because it embodies the values we think should animate tools in this ecosystem. dbt is hugely enabling for a important class of users, adapting software engineering principles to a slightly different domain with great ergonomics, and puts the graph of computations at the center of the data workflow.

<div align="center">
  <img
    src="/posts/dagster-and-dbt-better-together/dagster-dbt.png"
    alt="Dagster logo and dbt logo"
  />
</div>

People will sometimes ask us — should I use Dagster, or should I use dbt? We hope this integration helps make it clear that the right answer is _both_.

For users who already speak SQL, dbt’s tooling is unparalleled. For platform teams who run large dbt projects, Dagster makes it easy to operate dbt alongside your existing systems that share data assets with other processes — from Spark jobs to Jupyter notebooks and more.

With `dagster-dbt`, you can run dbt models and tests from within Dagster pipelines, letting you make use of dbt's extensive feature set and authoring capabilities alongside everything you expect from Dagster: robust, observable metadata, typed inputs and outputs, a tight dev loop, and operability. As your dbt project grows in scale, Dagster provides a toolbox for platform teams and analysts alike to debug and maintain complex workflows.

A huge thanks goes out to David Wallace ([@davidjwallace](https://twitter.com/davidjwallace)), whose community contributions laid the groundwork for `dagster-dbt`.

Please get in touch if you have also been working on integrations between Dagster and other tools that you might want to contribute back to open source. The core team is thrilled to help support you in contributing integrations back upstream.

If you’d like to start by exploring the full API, be sure to check out the [dbt docs](https://docs.getdbt.com/docs/introduction) and the `dagster-dbt` [API docs](https://docs.dagster.io/_apidocs/libraries/dagster_dbt). Or, keep reading for an example of how to run dbt commands with Dagster.

## Getting started with `dagster-dbt`

`dagster-dbt` provides Dagster solids that can run dbt commands either using a [dbt RPC server](https://docs.getdbt.com/reference/commands/rpc/) (Remote Procedure Call) or using the [dbt CLI](https://docs.getdbt.com/dbt-cli/cli-overview) (Command Line Interface).

If you’re only familiar with running dbt commands with the CLI, a dbt RPC server allows you to run commands against a dbt project over HTTP, as well as to poll the state of those commands or cancel them. The RPC server also allows for a deeper integration with Dagster, with more structured metadata surfaced to Dagster than is available through the CLI.

### Running dbt with the RPC server

`dagster-dbt` supports two kinds of execution:

- __synchronous__: Dagster invokes dbt over RPC and polls the server until the process completes.
- __asynchronous__: Dagster invokes dbt over RPC and immediately returns a request token corresponding to the invocation. This token can be used later to poll or cancel the dbt process.

The following example synchronously runs a dbt project via RPC and logs the results of each node of the dbt graph that was executed.

```python
from dagster import ModeDefinition, pipeline, solid
from dagster_dbt import DbtRpcPollResult, dbt_rpc_run_and_wait, local_dbt_rpc_resource


# Logs the execution result of each node in the dbt graph
@solid
def log_nodes(context, poll_result: DbtRpcPollResult):
    node_results = poll_result.results
    for node_result in node_results:
        context.log.info(
            "dbt Node {alias} completed in {execution_time:.3f}s with status: {status}".format(
                alias=node_result.node["alias"],
                execution_time=node_result.execution_time,
                status=node_result.status,
            )
        )


# Runs dbt via RPC and logs the execution results.
@pipeline(mode_defs=[ModeDefinition(resource_defs={"dbt_rpc": local_dbt_rpc_resource})])
def dbt_rpc_pipeline():
    log_nodes(dbt_rpc_run_and_wait())

```

__TODO__: Fix/add syntax highlighting for Python docstrings.

The dbt RPC solids extract metadata from each command invocation. All this information is available in the solids' output type, `DbtRpcPollResult`, and can be used as inputs to descendant solids.

We can pass arguments to the dbt run command by using [solid configs](https://docs.dagster.io/tutorial/basics_solids#specifying-config-for-pipeline-execution). You can set the solid config for your pipeline inside [Dagit](https://docs.dagster.io/overview/dagit), the Dagster web interface. In the YAML below, we specify a subset of dbt models to be run: sort_by_calories and least_caloric.

<div align="center">
  <img
    src="/posts/dagster-and-dbt-better-together/dbt_rpc_config.png"
    alt="Config for a dbt RPC solid"
    width="700px"
  />
</div>

Running this Dagster pipeline on our [dbt sample project](https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-dbt/dagster_dbt_tests/dagster_dbt_test_project) produces the following:

```bash
> dbt Node sort_by_calories completed in 0.124s with status: CREATE VIEW
> dbt Node least_caloric completed in 0.148s with status: CREATE VIEW
```

Using `context.log` is useful for debugging, but it doesn’t provide persistent records of dbt run results.

In `dagster-dbt`, the RPC solids also emit assets via `AssetMaterialization`s. These assets provide persistent, structured records of dbt's output across runs, and are automatically rendered in Dagit.

<div align="center">
  <img
    src="/posts/dagster-and-dbt-better-together/dbt_rpc_am.png"
    alt="AssetMaterialization from a dbt RPC solid"
    width="700px"
  />
</div>

Note that you will need to already have a running dbt RPC server in order to run the pipeline successfully. The `local_dbt_rpc_resource` will assume that your dbt RPC server is running on `localhost:8580`.

If you prefer to use a different port or to run your dbt RPC server on a remote host, you can explicitly configure the host and port of a `dbt_rpc_resource`:

```python
from dagster_dbt import dbt_rpc_resource

# ...some solid definitions

# An explicitly configured dbt RPC server resource.
custom_dbt_rpc_resource = dbt_rpc_resource.configured({
    "host": "80.80.80.80",
    "port": 8080,
})


# Runs dbt via RPC and logs the execution results.
@pipeline(mode_defs=[ModeDefinition(resource_defs={"dbt_rpc": custom_dbt_rpc_resource})])
def dbt_rpc_pipeline():
    log_nodes(dbt_rpc_run_and_wait())

```

See the `dagster-dbt` [API docs](https://docs.dagster.io/_apidocs/libraries/dagster_dbt) for more examples and a full list of Dagster solids for dbt RPC.

### Running dbt with the CLI

If you prefer not to manage a dbt RPC server, `dagster-dbt` can also invoke dbt commands via the CLI. The `dagster-dbt` CLI solids can be run in your local development environment without any server setup.

CLI output contains less metadata than the RPC output. Nevertheless, the CLI solids output useful statistics that summarize the results of your dbt process.

The following example executes dbt run in the shell and then logs summary information from the run results:

```python
from dagster import ModeDefinition, solid, pipeline
from dagster_dbt import DbtCliResult, dbt_cli_run


# Extracts and logs information from dbt run results.
@solid
def log_result(context, run_result: DbtCliResult):

    context.log.info(
        "Ran: {r.n_pass} passed, {r.n_warn} warned, {r.n_error} errored, {r.n_skip} skipped",
        r=run_result,
    )


# Executes `dbt run` in the shell and logs the result.
@pipeline
def dbt_cli_pipeline():
    log_result(dbt_cli_run())

```

Note that some required dbt CLI arguments must be defined in the solid config in order to run the pipeline successfully. You can set the solid config for your pipeline inside the Dagit web interface.

<div align="center">
  <img
    src="/posts/dagster-and-dbt-better-together/dbt_cli_config.png"
    alt="AssetMaterialization from a dbt RPC solid"
    width="700px"
  />
</div>

Running this Dagster pipeline in our sample dbt project produces the following:

```bash
> Ran: 2 passed, 0 warned, 0 errored, 0 skipped
```

Using `context.log` is useful for debugging, but doesn’t provide persistent records of dbt run results. Luckily, in `dagster-dbt`, the RPC solids also emit assets via `AssetMaterialization`s that persist across multiple executions of the Dagster pipeline.

As the pipeline executes, the CLI solids emit `AssetMaterialization`s containing CLI output and run results. These provide persistent records of CLI execution results, and are automatically rendered in Dagit.

<div align="center">
  <img
    src="/posts/dagster-and-dbt-better-together/dbt_cli_am.png"
    alt="AssetMaterialization from a dbt RPC solid"
    width="800px"
  />
</div>

See the `dagster-dbt` [API docs](https://docs.dagster.io/_apidocs/libraries/dagster_dbt) for more examples and a full list of Dagster solids for the dbt CLI.
